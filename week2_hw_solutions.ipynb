{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertical Stack:\n",
      " [[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  5  9]\n",
      " [10 11 12]]\n",
      "Horizontal Stack:\n",
      " [[ 1  2  3  7  5  9]\n",
      " [ 4  5  6 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define two custom numpy arrays A and B (as per lecture slides)\n",
    "A = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "B = np.array([[7, 5, 9], [10, 11, 12]])\n",
    "\n",
    "# 1. Stack Vertically and Horizontally\n",
    "vertical_stack = np.vstack((A, B))\n",
    "horizontal_stack = np.hstack((A, B))\n",
    "\n",
    "print(\"Vertical Stack:\\n\", vertical_stack)\n",
    "print(\"Horizontal Stack:\\n\", horizontal_stack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Elements: [5]\n"
     ]
    }
   ],
   "source": [
    "# 2. Find Common Elements Between A and B\n",
    "common_elements = np.intersect1d(A, B)\n",
    "print(\"Common Elements:\", common_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Numbers from A (Between 5 and 10): [5 6]\n"
     ]
    }
   ],
   "source": [
    "# 3. Extract Numbers from A Within a Specific Range (e.g., between 5 and 10)\n",
    "filtered_A = A[(A >= 5) & (A <= 10)]\n",
    "print(\"Filtered Numbers from A (Between 5 and 10):\", filtered_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 4. Load and Filter `iris_2d` Dataset Based on Conditions\u001b[39;00m\n\u001b[32m      2\u001b[39m url = \u001b[33m'\u001b[39m\u001b[33mhttps://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m iris_2d = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenfromtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfloat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Filter rows where petallength (3rd column) > 1.5 and sepallength (1st column) < 5.0\u001b[39;00m\n\u001b[32m      7\u001b[39m filtered_iris = iris_2d[(iris_2d[:, \u001b[32m2\u001b[39m] > \u001b[32m1.5\u001b[39m) & (iris_2d[:, \u001b[32m0\u001b[39m] < \u001b[32m5.0\u001b[39m)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/lib/_npyio_impl.py:1990\u001b[39m, in \u001b[36mgenfromtxt\u001b[39m\u001b[34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[39m\n\u001b[32m   1988\u001b[39m     fname = os.fspath(fname)\n\u001b[32m   1989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1990\u001b[39m     fid = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_datasource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1991\u001b[39m     fid_ctx = contextlib.closing(fid)\n\u001b[32m   1992\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/lib/_datasource.py:192\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(path, mode, destpath, encoding, newline)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[33;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[32m    157\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    188\u001b[39m \n\u001b[32m    189\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    191\u001b[39m ds = DataSource(destpath)\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/lib/_datasource.py:529\u001b[39m, in \u001b[36mDataSource.open\u001b[39m\u001b[34m(self, path, mode, encoding, newline)\u001b[39m\n\u001b[32m    526\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode=mode,\n\u001b[32m    527\u001b[39m                               encoding=encoding, newline=newline)\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m529\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data not found."
     ]
    }
   ],
   "source": [
    "# 4. Load and Filter `iris_2d` Dataset Based on Conditions\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "\n",
    "iris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3])\n",
    "\n",
    "# Filter rows where petallength (3rd column) > 1.5 and sepallength (1st column) < 5.0\n",
    "filtered_iris = iris_2d[(iris_2d[:, 2] > 1.5) & (iris_2d[:, 0] < 5.0)]\n",
    "print(\"Filtered Iris Data:\\n\", filtered_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Data (Every 20th Row):\n",
      "    Manufacturer    Model     Type\n",
      "0         Acura  Integra    Small\n",
      "20     Chrysler  LeBaron  Compact\n",
      "40        Honda  Prelude   Sporty\n",
      "60      Mercury   Cougar  Midsize\n",
      "80       Subaru   Loyale    Small\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load and Filter 'Manufacturer', 'Model', and 'Type' for Every 20th Row\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "# df = pd.read_csv('Cars93_miss.csv')\n",
    "\n",
    "filtered_df = df.loc[::20, ['Manufacturer', 'Model', 'Type']]\n",
    "print(\"Filtered Data (Every 20th Row):\\n\", filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data after replacing NaN values in Min.Price & Max.Price:\n",
      "   Min.Price  Max.Price\n",
      "0  12.900000  18.800000\n",
      "1  29.200000  38.700000\n",
      "2  25.900000  32.300000\n",
      "3  17.118605  44.600000\n",
      "4  17.118605  21.459091\n"
     ]
    }
   ],
   "source": [
    "# 2. Replace Missing Values in 'Min.Price' and 'Max.Price' with Their Respective Mean\n",
    "df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda col: col.fillna(col.mean()))\n",
    "print(\"\\nData after replacing NaN values in Min.Price & Max.Price:\")\n",
    "print(df[['Min.Price', 'Max.Price']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows with Sum Greater than 100:\n",
      "      0   1   2   3\n",
      "0   39  37  12  19\n",
      "2   27  39  33  25\n",
      "4   30  33  32  39\n",
      "6   23  22  25  38\n",
      "10  39  28  16  27\n",
      "12  37  32  20  17\n",
      "14  31  22  31  18\n"
     ]
    }
   ],
   "source": [
    "# 3. Get Rows Where Row Sum > 100\n",
    "df_random = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))\n",
    "\n",
    "filtered_rows = df_random[df_random.sum(axis=1) > 100]\n",
    "print(\"\\nRows with Sum Greater than 100:\\n\", filtered_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
